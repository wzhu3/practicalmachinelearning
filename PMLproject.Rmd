---
title: "Practical Machine Learning Project: Prediction Assignment Writeup"
author: "WZ"
output: html_document
---

### Synopsis
The aim of this work is to predict the quality of weight lifting exercises, using data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. We will evalute the in sample and out sample errors of various predition models, and use the best modle to predict 20 different test cases.
The data for this project come from this [source](http://groupware.les.inf.puc-rio.br/har).

### Data Cleaning
A quick inspection of the train and test data sets identified many NA.  This is particular true for the test set, in which 100 of the 160 variables contained NA only.  While the train data set also contains lots of NA, there is 0 variable that is entirely NA.  We will remove the 100 variables with entirely NA  in the test set and only inlcluded the remaining variables in modle building, evaluation, and prediction. This is simply due to the fact that we can not use the variables with NA entirely for prediction. We also removed the first two variables that contained the participants identification. At the end, 57 variables were included in the initial phase of model building.
We had a large train data set.  I used 80% for model building and 20% for cross validation.

```{r setup}
knitr::opts_chunk$set(echo = F)
```

```{r load packages}
require(caret)
require(rpart)
require(randomForest)
```

```{r }
knitr::opts_chunk$set(echo = TRUE)
```

```{r data preparation}

train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")

ncol(test[ , ! apply( test, 2 , function(x) all(is.na(x)) ) ])
ncol(train[ , ! apply( train, 2 , function(x) all(is.na(x)) ) ])

test1 <- test[ , ! apply( test, 2 , function(x) all(is.na(x)) ) ]
test1 <- test1[,3:60]
train1 <- train[,names(train) %in% names(test1)]
train1$classe <- train$classe
names(train1)

set.seed(128)
training_i <- createDataPartition(y=train1$classe, p=0.8, list=FALSE)
training <- train1[training_i,]
cv <- train1[-training_i,]
dim(test1)
dim(training)
dim(cv)

```
### Model Building
I evaluated the perpormance of the following two algorithms. 


1. Decision trees with CART (rpart).
2. Random forest decision trees (randomForest).

Package rpart was used here since it appeared to be much faster that the corresponding caret package method. The 'rf' train method of the caret package was used since I had difficulties using the randomForest package in predicting the test data. A three fold validation is used in the random forest model.

```{r Model}
m_cart <- rpart(classe ~ ., method='class', data = training)
printcp(m_cart)

m_rf <- train(classe ~ ., 
              data = training,
              method='rf',
              trControl = trainControl(method = "cv", number = 3),
              importance=TRUE)

print(m_rf)

```
### Out of Sample Errors
Out Of sample errors of the above three models were assessed using the predict function on the train data partitioned for cross validation.


```{r ose}

p_cart <- predict(m_cart, newdata = cv, type='class')
cm_cart <- table(cv$classe, p_cart)
a_cart <- sum(cm_cart[row(cm_cart) == col(cm_cart)])/sum(cm_cart)

p_rf <- predict(m_rf, newdata = cv)
cm_rf <- table(cv$classe, p_rf)
a_rf <- sum(diag(cm_rf))/sum(cm_rf)

output <- data.frame(Model = c('CART','Random Forest'),
                     Accuracy = c(round(a_cart,3), round(a_rf,3)),
                     Error = c(round(1-a_cart,3), round(1-a_rf,3))
)
output

```
### Variabl Importance 
Top 9 most important features identified by the random forest models are shown in the figure below.


```{r figure}
plot(varImp(m_rf),top =9, main="Nine Most Important Features Identified by the RF Algorithm")
```

###Prediction
I compared the prediction results of both the CART and random forest models using the test data set of 20 observations.

```{r prediction}
test_cart <- predict(m_cart, newdata=test1,type='class')
test_rf <- predict(m_rf, newdata = test1)

TestPrediction <- data.frame(problem_id = test1$problem_id,
                             CART_pred = test_cart,
                             RF_pred = test_rf)

TestPrediction

sum(TestPrediction[,2] == TestPrediction[,3])

```
###Conclusion
The random forest model outperformed the CART model in classification of the weight lift patterns, judging by the out of sample error rates.However, the computation is significant shorter for theCART algorithms in the rpart package. There is a 90% agreement between the CART and random forest prediction on the 20 test observation (18/20).


